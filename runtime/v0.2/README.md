
# IKDD Runtime v0.2 â€” Hybrid AI Runtime

âœ… v0.2 runtime is **self-contained** and **version isolated**.

```
IKDD_Runtime/
  â”œâ”€ runtime/
  â”‚   â””â”€ v0.2/
  â”‚       â”œâ”€ ikdd/          â† hybrid runtime source
  â”‚       â”œâ”€ generated/     â† output source from runtime
  â”‚       â”œâ”€ tool.yaml      â† required by v0.2 runtime
  â”‚       â””â”€ knowledge.yaml â† required by v0.2 runtime
```

## Usage

### Basic (Dummy Provider)

```bash
cd runtime/v0.2
python -m ikdd.cli \
  --tool tool.yaml \
  --knowledge knowledge.yaml \
  --provider dummy \
  --outdir generated
```

### With Anthropic Claude

```bash
# Install dependency
pip install anthropic

# Set API key
export ANTHROPIC_API_KEY="your-api-key-here"

# Run with anthropic provider
cd runtime/v0.2
python -m ikdd.cli \
  --tool tool.yaml \
  --knowledge knowledge.yaml \
  --provider anthropic \
  --outdir generated
```

### Provider Options

- `dummy` â€” Reference implementation (no external API, uses hardcoded template)
- `anthropic` â€” Uses Anthropic Claude API (requires `anthropic` package and `ANTHROPIC_API_KEY`)
- `openai` â€” OpenAI stub (not implemented)

## Testing

ðŸ“– **Comprehensive Testing Guide**: See [TESTING_GUIDE.md](TESTING_GUIDE.md) for detailed testing instructions.

### Quick Start Testing Without API Connection

You can validate the runtime implementation without any API connection using the test suite:

```bash
cd runtime/v0.2
python test_generated_code.py
```

This test script:
1. âœ… Generates code using the `dummy` provider
2. âœ… Validates all CDD constraints are satisfied
3. âœ… Executes the generated code with test data
4. âœ… Verifies correct output

**No API key required** â€” Perfect for CI/CD pipelines and local development.

### Provider Comparison

Compare outputs from different providers:

```bash
# Test single provider
python compare_providers.py dummy

# Compare dummy vs anthropic (requires ANTHROPIC_API_KEY)
python compare_providers.py dummy anthropic
```

This tool shows:
- âœ… Generation success/failure for each provider
- âœ… Execution success/failure
- âœ… Code metrics (lines of code, output rows)
- âœ… Side-by-side comparison of outputs

### Manual Testing

You can also test manually:

```bash
# Generate code
python -m ikdd.cli --tool tool.yaml --knowledge knowledge.yaml --provider dummy --outdir generated

# Create test data
echo "name,score,category
Alice,85,A
Bob,45,B
Charlie,92,A" > test.csv

# Run generated code
python -c "
from generated.csv_filter_exporter import csv_filter_exporter
csv_filter_exporter('test.csv', 'score', 50, 'output.json')
"

# Check output
cat output.json
```
